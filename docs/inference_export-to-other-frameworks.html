---

title: Export To Other Frameworks

keywords: fastai
sidebar: home_sidebar

summary: "The ONNX exporter works without hiccups. To export to CoreML or TensorFlow, you need to fiddle with different versions of the underlying libraries"
description: "The ONNX exporter works without hiccups. To export to CoreML or TensorFlow, you need to fiddle with different versions of the underlying libraries"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/04_inference_export-to-other-frameworks.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">




</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To go from <code>PyTorch</code> to any other framework, the model needs to first be convert to <code>ONNX</code> format. <br>
<code>PyTorch</code> has native support for this conversion, and to transfer to any other framework, the conversion will be made from <code>ONNX</code> -&gt; other framework. <br></p>
<p><strong>Note:</strong> Conversion from <code>PyTorch</code> to <code>ONNX</code> is one way i.e. models cannot be converted from <code>ONNX</code> to <code>PyTorch</code></p>
<p>For CoreML compatibility, you need to change fastai's <code>Flatten</code> to <code>torch</code>'s <code>nn.Flatten()</code></p>

</div>
</div>
</div>
    {% raw %}

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">224</span><span class="p">,</span><span class="mi">224</span><span class="p">)</span>

<span class="n">out1</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
<span class="n">out2</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">out1</span><span class="p">,</span><span class="n">out2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As this notebook goes along, we'll look at model predictions on the same image across frameworks. <br>
Performance is not necessarily replicated 100% as you transfer across frameworks. In my observations, the change in <code>ONNX</code> is negligible, whereas the precision loss in <code>CoreML</code> is greater. <br>
I'm not sure why that is -- intuition suggests that it's how CoreML does the normalisation internally.</p>
<p>For completeness' sake, we will first reproduce the model's predictions in PyTorch. <br>
Fastai typically does center-crop on the validation set images, but I intentionally leave that out here, as the model I'm using was trained without any cropping.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Pre-Processing-&amp;-Predicting-in-PyTorch">Pre-Processing &amp; Predicting in PyTorch<a class="anchor-link" href="#Pre-Processing-&amp;-Predicting-in-PyTorch"> </a></h3>
</div>
</div>
</div>
    {% raw %}

<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="preprocess_one" class="doc_header"><code>preprocess_one</code><a href="https://github.com/rsomani95/fastai2_extensions/tree/master/fastai2_extensions/inference/export.py#L19" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>preprocess_one</code>(<strong><code>fname</code></strong>:<code>Union</code>[<code>str</code>, <code>Path</code>])</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="preprocess_batch" class="doc_header"><code>preprocess_batch</code><a href="https://github.com/rsomani95/fastai2_extensions/tree/master/fastai2_extensions/inference/export.py#L28" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>preprocess_batch</code>(<strong><code>fnames</code></strong>:<code>Union</code>[<code>str</code>, <code>Path</code>, <code>Collection</code>[<code>T_co</code>]])</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path_imgs</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;/Users/rahulsomani/Desktop/lighting-cast/&#39;</span><span class="p">)</span>
<span class="n">files</span> <span class="o">=</span> <span class="n">get_image_files</span><span class="p">(</span><span class="n">path_imgs</span><span class="p">)</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">files</span><span class="p">[</span><span class="mi">120</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">preprocess_one</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="n">torch_pred</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">torch_pred</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[0.7403, 0.2597]], grad_fn=&lt;SoftmaxBackward&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Export-to-ONNX">Export to ONNX<a class="anchor-link" href="#Export-to-ONNX"> </a></h3><p>Inspired by Ross Wightman's script <a href="https://github.com/rwightman/gen-efficientnet-pytorch/blob/master/onnx_export.py">https://github.com/rwightman/gen-efficientnet-pytorch/blob/master/onnx_export.py</a></p>

</div>
</div>
</div>
    {% raw %}

<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="torch_to_onnx" class="doc_header"><code>torch_to_onnx</code><a href="https://github.com/rsomani95/fastai2_extensions/tree/master/fastai2_extensions/inference/export.py#L44" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>torch_to_onnx</code>(<strong><code>model</code></strong>:<code>Module</code>, <strong><code>activation</code></strong>:<code>Module</code>=<em><code>None</code></em>, <strong><code>save_path</code></strong>:<code>str</code>=<em><code>'../exported-models/'</code></em>, <strong><code>model_fname</code></strong>:<code>str</code>=<em><code>'onnx-model'</code></em>, <strong><code>input_shape</code></strong>:<code>tuple</code>=<em><code>(1, 3, 224, 224)</code></em>, <strong><code>input_name</code></strong>:<code>str</code>=<em><code>'input_image'</code></em>, <strong><code>output_names</code></strong>:<code>Union</code>[<code>str</code>, <code>list</code>]=<em><code>'output'</code></em>, <strong>**<code>export_args</code></strong>)</p>
</blockquote>

<pre><code>Export a `nn.Module` -&gt; ONNX

This function exports the model with support for batching,
checks that the export was done properly, and polishes the
model up (removes unnecessary fluff added during conversion)

Key Arguments
=============
* activation:  If not None, append this to the end of your model.
               Typically a `nn.Softmax(-1)` or `nn.Sigmoid()`
* input_shape: Shape of the inputs to the model</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch_to_onnx</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
              <span class="n">activation</span>   <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
              <span class="n">save_path</span>    <span class="o">=</span> <span class="s1">&#39;/Users/rahulsomani/Desktop/&#39;</span><span class="p">,</span>
              <span class="n">model_fname</span>  <span class="o">=</span> <span class="s1">&#39;lighting-cast&#39;</span><span class="p">,</span>
              <span class="n">output_names</span> <span class="o">=</span> <span class="s1">&#39;lighting-cast&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Loading, polishing, and optimising exported model from /Users/rahulsomani/Desktop/lighting-cast.onnx
Exported successfully
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="ONNX-Inference">ONNX Inference<a class="anchor-link" href="#ONNX-Inference"> </a></h3>
</div>
</div>
</div>
    {% raw %}

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">onnxruntime</span> <span class="kn">import</span> <span class="n">InferenceSession</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="torch_to_numpy" class="doc_header"><code>torch_to_numpy</code><a href="https://github.com/rsomani95/fastai2_extensions/tree/master/fastai2_extensions/inference/export.py#L93" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>torch_to_numpy</code>(<strong><code>x</code></strong>:<code>tensor</code>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">onnx_model_path</span> <span class="o">=</span> <span class="s1">&#39;/Users/rahulsomani/Desktop/lighting-cast.onnx&#39;</span>
<span class="n">session</span> <span class="o">=</span> <span class="n">InferenceSession</span><span class="p">(</span><span class="n">onnx_model_path</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">{</span><span class="n">session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
     <span class="n">torch_to_numpy</span><span class="p">(</span><span class="n">preprocess_one</span><span class="p">(</span><span class="n">f</span><span class="p">))}</span>

<span class="n">preds_onnx</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">preds_onnx</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[array([[0.74026996, 0.25973007]], dtype=float32)]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Batch-vs-Single-Image-Prediction-Comparison">Batch vs Single Image Prediction Comparison<a class="anchor-link" href="#Batch-vs-Single-Image-Prediction-Comparison"> </a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This code chunk demonstrates that batching works with the <code>ONNX</code> model. <br>
Interestingly, loading and predicting one image at a time seems to be faster on a CPU. For reference, these tests were done on an Early 2015 MacBookPro 13-inch.</p>

</div>
</div>
</div>
    {% raw %}

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>it
<span class="n">x</span> <span class="o">=</span> <span class="p">{</span><span class="n">session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
     <span class="n">torch_to_numpy</span><span class="p">(</span><span class="n">preprocess_batch</span><span class="p">(</span><span class="n">files</span><span class="p">[:</span><span class="mi">10</span><span class="p">]))}</span>

<span class="n">preds_onnx</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>364 ms ± 32.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>it
<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">files</span><span class="p">[:</span><span class="mi">10</span><span class="p">]:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="p">{</span><span class="n">session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
         <span class="n">torch_to_numpy</span><span class="p">(</span><span class="n">preprocess_one</span><span class="p">(</span><span class="n">f</span><span class="p">))}</span>
    <span class="n">preds_onnx</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>330 ms ± 22.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Export-to-TensorFlow">Export to TensorFlow<a class="anchor-link" href="#Export-to-TensorFlow"> </a></h3><p>This can be a painful process, especially due to the many different versions of tensorflow and separate issues for each of them. <br>
After much trial and error, what worked for me was installing <code>tensorflow==1.15</code> and the accompanying <code>onnx-tf</code> version <a href="https://github.com/onnx/onnx-tensorflow/tree/tf-1.x">from source</a></p>

</div>
</div>
</div>
    {% raw %}

<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="onnx_to_tf" class="doc_header"><code>onnx_to_tf</code><a href="https://github.com/rsomani95/fastai2_extensions/tree/master/fastai2_extensions/inference/export.py#L102" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>onnx_to_tf</code>(<strong><code>onnx_model</code></strong>:<code>Union</code>[<code>str</code>, <code>Path</code>], <strong><code>output_path</code></strong>:<code>Union</code>[<code>str</code>, <code>Path</code>])</p>
</blockquote>

<pre><code>Simplest wrapper around https://github.com/onnx/onnx-tensorflow/blob/master/example/onnx_to_tf.py
Ensure `output_path` includes `.pb` as the file extension</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="TensorFlow-Inference">TensorFlow Inference<a class="anchor-link" href="#TensorFlow-Inference"> </a></h3>
</div>
</div>
</div>
    {% raw %}

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tf_rep</span> <span class="o">=</span> <span class="n">onnx_to_tf</span><span class="p">(</span><span class="n">onnx_model</span><span class="o">=</span><span class="n">onnx_model_path</span><span class="p">,</span> <span class="n">output_path</span><span class="o">=</span><span class="s1">&#39;/Users/rahulsomani/Desktop/lighting-cast.pb&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch_to_numpy</span><span class="p">(</span><span class="n">preprocess_one</span><span class="p">(</span><span class="n">f</span><span class="p">))</span>
<span class="n">tf_preds</span> <span class="o">=</span> <span class="n">tf_rep</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">tf_preds</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Outputs(_0=array([[0.74027056, 0.2597295 ]], dtype=float32))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Export-to-CoreML">Export to CoreML<a class="anchor-link" href="#Export-to-CoreML"> </a></h3><p>Most of the code here is borrowed from two authors:</p>
<ol>
<li>David Pfahler: <a href="https://forums.fast.ai/t/running-a-fastai-model-in-ios-using-coreml/57553">https://forums.fast.ai/t/running-a-fastai-model-in-ios-using-coreml/57553</a></li>
<li>Matthijs Hollemans' <a href="https://leanpub.com/coreml-survival-guide">CoreML Survival Guide</a></li>
</ol>

</div>
</div>
</div>
    {% raw %}

<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;coremltools version: </span><span class="si">{coremltools.__version__}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;onnx-coreml version: </span><span class="si">{onnx_coreml.__version__}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>coremltools version: 3.3
onnx-coreml version: 1.3
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_nn_spec" class="doc_header"><code>get_nn_spec</code><a href="https://github.com/rsomani95/fastai2_extensions/tree/master/fastai2_extensions/inference/export.py#L122" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_nn_spec</code>(<strong><code>spec</code></strong>)</p>
</blockquote>

<pre><code>spec is of type `Model_pb2.Model`, accessed via coreml_model.get_spec()</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">spec</span> <span class="o">=</span> <span class="n">coreml_model</span><span class="o">.</span><span class="n">get_spec</span><span class="p">()</span>
<span class="n">nn</span>   <span class="o">=</span> <span class="n">get_nn_spec</span><span class="p">(</span><span class="n">spec</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># store away old layers to add back to the reconstructed network</span>
<span class="n">old_layers</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>
<span class="k">del</span> <span class="n">nn</span><span class="o">.</span><span class="n">layers</span><span class="p">[:]</span>

<span class="c1"># names of inputs and outputs of the scaling layer</span>
<span class="n">input_name</span>  <span class="o">=</span> <span class="n">old_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">output_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{input_name}</span><span class="s2">_scaled&quot;</span>

<span class="c1"># create and add scaling layer to new network</span>
<span class="n">scale_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
<span class="n">scale_layer</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;scale_layer&quot;</span>
<span class="n">scale_layer</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_name</span><span class="p">)</span>
<span class="n">scale_layer</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_name</span><span class="p">)</span>

<span class="n">scale_layer</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">floatValue</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span>
    <span class="mi">1</span><span class="o">/</span><span class="n">red_sdev</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="n">green_sdev</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="n">blue_sdev</span>
<span class="p">])</span>
<span class="n">scale_layer</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">shapeScale</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># add back all the old layers</span>
<span class="n">nn</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">old_layers</span><span class="p">)</span>
<span class="n">nn</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_name</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">coreml_path</span> <span class="o">=</span> <span class="s1">&#39;/Users/rahulsomani/Desktop/lighting-cast.mlmodel&#39;</span>
<span class="n">coremltools</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">save_spec</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">coreml_path</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="onnx_to_coreml" class="doc_header"><code>onnx_to_coreml</code><a href="https://github.com/rsomani95/fastai2_extensions/tree/master/fastai2_extensions/inference/export.py#L130" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>onnx_to_coreml</code>(<strong><code>onnx_path</code></strong>:<code>Union</code>[<code>str</code>, <code>Path</code>], <strong><code>normalise_mean</code></strong>:<code>Collection</code>[<code>T_co</code>]=<em><code>[0.485, 0.456, 0.406]</code></em>, <strong><code>normalise_sdev</code></strong>:<code>Collection</code>[<code>T_co</code>]=<em><code>[0.229, 0.224, 0.225]</code></em>, <strong><code>is_bgr</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>mode</code></strong>:<code>Optional</code>[<code>str</code>]=<em><code>'classifier'</code></em>, <strong><code>class_labels</code></strong>:<code>Optional</code>[<code>Collection</code>[<code>T_co</code>]]=<em><code>None</code></em>, <strong><code>image_input_names</code></strong>=<em><code>['input_image']</code></em>, <strong><code>minimum_ios_deployment_target</code></strong>=<em><code>'11.2'</code></em>, <strong><code>output_path</code></strong>=<em><code>''</code></em>)</p>
</blockquote>

<pre><code>Add a custom scaling layer with the `normalise_mean` and
`normalise_sdev` stats, do the appropriate preprocessing
and export an onnx-model to CoreML.

Ensure that the `output_path` includes the `.mlmodel` extension</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="CoreML-Inference">CoreML Inference<a class="anchor-link" href="#CoreML-Inference"> </a></h3>
</div>
</div>
</div>
    {% raw %}

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%capture</span>
<span class="n">coreml_model</span> <span class="o">=</span> <span class="n">onnx_to_coreml</span><span class="p">(</span><span class="n">onnx_path</span>   <span class="o">=</span> <span class="s1">&#39;/Users/rahulsomani/Desktop/lighting-cast.onnx&#39;</span><span class="p">,</span>
                              <span class="n">output_path</span> <span class="o">=</span> <span class="s1">&#39;/Users/rahulsomani/Desktop/lighting-cast.mlmodel&#39;</span><span class="p">,</span>
                              <span class="n">class_labels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">dls</span><span class="o">.</span><span class="n">vocab</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">coreml_preds</span> <span class="o">=</span> <span class="n">coreml_model</span><span class="o">.</span><span class="n">predict</span><span class="p">({</span><span class="s1">&#39;input_image&#39;</span><span class="p">:</span> <span class="n">open_image</span><span class="p">(</span><span class="n">f</span><span class="p">)})</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">coreml_preds</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;classLabel&#39;: &#39;shot_lighting_cast_hard&#39;,
 &#39;lighting-cast&#39;: {&#39;shot_lighting_cast_hard&#39;: 0.7405732274055481,
                   &#39;shot_lighting_cast_soft&#39;: 0.2594267427921295}}
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Compare-Preds-Across-Frameworks">Compare Preds Across Frameworks<a class="anchor-link" href="#Compare-Preds-Across-Frameworks"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The predictions</p>

</div>
</div>
</div>
    {% raw %}

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fastai_pred</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">f</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">coreml_preds</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">coreml_preds</span><span class="p">[</span><span class="s1">&#39;lighting-cast&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FastAI:     {fastai_pred[0].item(), fastai_pred[1].item()}&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;PyTorch:    {torch_pred[0][0].item(), torch_pred[0][1].item()}&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ONNX:       {preds_onnx[0][0][0], preds_onnx[0][0][1]}&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;CoreML:     {coreml_preds[0], coreml_preds[1]}&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TensorFlow: </span><span class="si">{tf_preds[0][0]}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>FastAI:     (0.7402700185775757, 0.2597300112247467)
PyTorch:    (0.7402703166007996, 0.25972968339920044)
ONNX:       (0.74026996, 0.25973007)
CoreML:     (0.7405732274055481, 0.2594267427921295)
TensorFlow: [0.74027056 0.2597295 ]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
