# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/interpret_gradcam.ipynb (unless otherwise specified).

__all__ = ['Hook', 'HookBwd', 'create_test_img', 'to_cuda', 'get_label_idx', 'get_target_layer', 'compute_gcam_items',
           'compute_gcam_map', 'plt2pil', 'plt_decoded', 'plot_gcam', 'plot_gcam_maps', 'GradCam', 'PathLike']

# Cell
from fastai.vision.all import *
from typing import List, Tuple, Callable, Union, Optional, Any

# Cell
class Hook():
    def __init__(self, m):
        self.hook = m.register_forward_hook(self.hook_func)
    def hook_func(self, m, inp, out):  self.stored = out.detach().clone()
    def __enter__(self, *args): return self
    def __exit__ (self, *args): self.hook.remove()

class HookBwd():
    def __init__(self,m):
        self.hook = m.register_backward_hook(self.hook_func)
    def hook_func(self, model, grad_in, grad_out): self.stored = grad_out[0].detach().clone()
    def __enter__(self, *args): return self
    def __exit__ (self, *args): self.hook.remove()

# Cell
def create_test_img(learn, f, return_img=True):
    img = PILImage.create(f)
    x = first(learn.dls.test_dl([f]))
    x = x[0]
    if return_img: return img,x
    return x

# Cell
def to_cuda(*args): [o.cuda() for o in args]
def get_label_idx(learn:Learner, preds:torch.Tensor,
                  label:Union[str,int,None]) -> Tuple[int,str]:
    """Either:
    * Get the label idx of a specific `label`
    * Get the max pred using `learn.loss_func.decode` and `learn.loss_func.activation`
        * Only works for `softmax` activations as the backward pass requires a scalar index
        * Throws a `RuntimeError` if the activation is a `sigmoid` activation
    """
    if label is not None:
        # if `label` is a string, check that it exists in the vocab
        # and return the label's index
        if isinstance(label,str):
            if not label in learn.dls.vocab: raise ValueError(f"'{label}' is not part of the Learner's vocab: {learn.dls.vocab}")
            return learn.dls.vocab.o2i[label], label
        # if `label` is an index, return itself
        elif isinstance(label,int): return label, learn.dls.vocab[label]
        else: raise TypeError(f"Expected `str`, `int` or `None`, got {type(label)} instead")
    else:
        # if no `label` is specified, check that `learn.loss_func` has `decodes`
        # and `activation` implemented, run the predictions through them,
        # then check that the output length is 1. If not, the activation must be
        # sigmoid, which is incompatible
        if not hasattr(learn.loss_func, 'activation') or\
           not hasattr(learn.loss_func, 'decodes'):
            raise NotImplementedError(f"learn.loss_func does not have `.activation` or `.decodes` methods implemented")
        decode_pred = compose(learn.loss_func.activation, learn.loss_func.decodes)
        label_idx   = decode_pred(preds)
        if len(label_idx) > 1:
            raise RuntimeError(f"Output label idx must be of length==1. If your loss func has a sigmoid activation, please specify `label`")
        return label_idx, learn.dls.vocab[label_idx][0]

def get_target_layer(learn: Learner,
                     target_layer:Union[nn.Module, Callable, None]) -> nn.Module:
    if target_layer is None:
        if has_pool_type(learn.model[0]):
            warnings.warn(f"Detected a pooling layer in the model body. Unless this is intentional, ensure that the feature map is not flattened")
        return learn.model[0]
    elif isinstance(target_layer, nn.Module):
        return target_layer
    elif callable(target_layer):
        return target_layer(learn.model)

def compute_gcam_items(learn: Learner,
                       x: TensorImage,
                       label: Union[str,int,None] = None,
                       target_layer: Union[nn.Module, Callable, None] = None
                      ) -> Tuple[torch.Tensor]:
    """Compute gradient and activations of `target_layer` of `learn.model`
    for `x` with respect to `label`.

    If `target_layer` is None, then it is set to `learn.model[:-1]`
    """
    to_cuda(learn.model, x)
    target_layer = get_target_layer(learn, target_layer)
    with HookBwd(target_layer) as hook_g:
        with Hook(target_layer) as hook:
            preds       = learn.model.eval()(x)
            activations = hook.stored
            label_idx, label = get_label_idx(learn,preds,label)
            #print(preds.shape, label, label_idx)
            #print(preds)
        preds[0, label_idx].backward()
        gradients = hook_g.stored

    preds = getattr(learn.loss_func, 'activation', noop)(preds)

    # remove leading batch_size axis
    gradients   = gradients  [0]
    activations = activations[0]
    preds       = preds.detach().cpu().numpy().flatten()
    return gradients, activations, preds, label

# Cell
def compute_gcam_map(gradients, activations) -> torch.Tensor:
    """Take the mean of `gradients`, multiply by `activations`,
    sum it up and return a GradCAM feature map
    """
    # Mean over the feature maps. If you don't use `keepdim`, it returns
    # a value of shape (1280) which isn't amenable to `*` with the activations
    gcam_weights = gradients.mean(dim=[1,2], keepdim=True) # (1280,7,7)   --> (1280,1,1)
    gcam_map     = (gcam_weights * activations) # (1280,1,1) * (1280,7,7) --> (1280,7,7)
    gcam_map     = gcam_map.sum(0)              # (1280,7,7) --> (7,7)
    return gcam_map

# Cell
import PIL
def plt2pil(fig) -> PIL.Image.Image:
    buf = io.BytesIO()
    fig.savefig(buf, bbox_inches='tight', pad_inches=0)
    buf.seek(0)
    pil_img = PIL.Image.open(buf).convert('RGB')
    plt.close('all')
    return pil_img

def plt_decoded(learn, x, ctx):
    'Processed tensor --> plottable image, return `extent`'
    x_decoded = TensorImage(learn.dls.train.decode((x,))[0][0])
    extent = (0, x_decoded.shape[1], x_decoded.shape[2], 0)
    x_decoded.show(ctx=ctx)
    return extent

def plot_gcam(learn, img:PILImage, x:tensor, gcam_map:tensor, plt_axis=None,
              full_size=True, alpha=0.6, dpi=100,
              interpolation='bilinear', cmap='magma', **kwargs):
    'Plot gradcam on `plt_axis`'
    fig,ax = plt.subplots(dpi=dpi, **kwargs)
    if full_size:
        extent = (0, img.width,img.height, 0)
        show_image(img, ctx=ax)
    else:
        extent = plt_decoded(learn, x, ax)#plt_axis)

    show_image(gcam_map.detach().cpu(), ctx=ax,
               alpha=alpha, extent=extent,
               interpolation=interpolation, cmap=cmap)

    return plt2pil(fig)
#     buf = io.BytesIO()
#     fig.savefig(buf, bbox_inches='tight', pad_inches=0)
#     buf.seek(0)
#     pil_img = PIL.Image.open(buf).convert('RGB')
#     plt.close('all')
#     return pil_img

# Cell
from typing import Dict
def plot_gcam_maps(
    learn:Learner, labels:List[str], _label:str, img:PILImage, x:TensorImage,
    preds_dict:Dict[str,float], gradcams:Dict[str,torch.Tensor],
    ## plotting args
    max_ncols=None, full_size=True, alpha=0.6,
    interpolation='bilinear', cmap='magma',
    figsize=(12,12), return_fig=False, plot_original=False
):
    """
    Plot the computed Grad-CAMs.

    Key Arguments
    -------------
    * full_size: If True, plots the images in their original size, else
                 in the size that the `Learner` resizes them to
    * plot_original: if True, plots the original image without any overlays
                     in addition to the heatmaps
    * max_ncols: Use this to manipulate the number of rows you'd like your
                 plot to have. Useful for classifiers with a large no. of
                 outputs. Enter `None` to plot everything in one row.
    """
    label_idx = 0
    total = len(labels)+1 if plot_original else len(labels)

    if max_ncols is None:
        max_ncols=len(labels)+1 if plot_original else len(labels)

    if total > max_ncols:
        nrows  = math.ceil(total/max_ncols)
        fig,ax = plt.subplots(nrows=nrows, ncols=max_ncols, figsize=figsize)
        plt.axis('off')
        plt.tight_layout()

        for i in range(nrows):
            for j in range(max_ncols):
                if plot_original:
                    if i==0 and j==0:
                        if full_size:
                            show_image(img, ctx=ax[0,0])
                        else:
                            x = TensorImage(learn.dls.train.decode((x,))[0][0])
                            x.show(ctx=ax[0,0])
                        ax[0][0].set_title('original')
                        continue
                plot_gcam(img=img, x=x, full_size=full_size,
                          gcam_map=gradcams[labels[label_idx]],
                          plt_axis=ax[i,j], alpha=alpha, learn=learn,
                          interpolation=interpolation, cmap=cmap)
                title = labels[label_idx]
                ax[i][j].set_title(f'{title}, {preds_dict[title] * 100:.02f}%')
                label_idx += 1
                if label_idx >= len(labels): break
    else:
        fig,ax = plt.subplots(nrows=1, ncols=max_ncols, figsize=figsize)
        plt.axis('off')
        plt.tight_layout()

        if max_ncols==1: ax=[ax]
        for i in range(len(ax)):
            if plot_original:
                if i==0 and full_size:
                    show_image(img, ctx=ax[0])
                    ax[0].set_title('original')
                    continue
                elif i==0 and not full_size:
                    _ = plt_decoded(learn, x, ctx=ax[0])
                    ax[0].set_title('original')
                    continue
            plot_gcam(img=img, x=x, full_size=full_size,
                      gcam_map=gradcams[labels[label_idx]],
                      plt_axis=ax[i], alpha=alpha, learn=learn,
                      interpolation=interpolation, cmap=cmap)
            title = labels[label_idx]
            if title is None: title=_label
            ax[i].set_title(f'{title}, {preds_dict[title] * 100:.02f}%')
            label_idx += 1

# Cell
import math
from typing import List
PathLike = Union[str,Path]

class GradCam():
    "Class interface to facilitate computing and siplaying Grad-CAM"
    def __init__(self, learn:Learner, fname:PathLike, labels:Union[str,List[str],None]):
        """
        Compute Grad-CAM maps for all `labels`.
        If `labels` is None, compute for the predicted class (more expensive)
        """
        self.learn = learn
        self.fname = fname
        self.img, self.x = create_test_img(self.learn, self.fname)
        if labels is None:
            self.labels = [self.learn.predict(fname)[0]]
        else:
            self.labels = [labels] if isinstance(labels,str) else labels
        self.compute_gcams()

    def compute_gcams(self):
        self.gradcams = defaultdict()
        for label in self.labels:
            gradients, activations, self.preds = compute_gcam_items(self.learn,self.x,label)
            gcam_map = compute_gcam_map(gradients, activations)
            self.gradcams[label] = gcam_map
            self.preds_dict = {
                lab:pred for pred,lab in zip(self.preds, self.learn.dls.vocab)
            }

    def plot(self, max_ncols=None, full_size=True, alpha=0.6,
             interpolation='bilinear', cmap='magma',
             figsize=(12,12), return_fig=False, plot_original=False):
        """
        Plot the computed Grad-CAMs.

        Key Arguments
        -------------
        * full_size: If True, plots the images in their original size, else
                     in the size that the `Learner` resizes them to
        * plot_original: if True, plots the original image without any overlays
                         in addition to the heatmaps
        * max_ncols: Use this to manipulate the number of rows you'd like your
                     plot to have. Useful for classifiers with a large no. of
                     outputs. Enter `None` to plot everything in one row.
        """
        label_idx = 0
        total = len(self.labels)+1 if plot_original else len(self.labels)

        if max_ncols is None:
            max_ncols=len(self.labels)+1 if plot_original else len(self.labels)

        if total > max_ncols:
            nrows  = math.ceil(total/max_ncols)
            fig,ax = plt.subplots(nrows=nrows, ncols=max_ncols, figsize=figsize)
            plt.axis('off')

            for i in range(nrows):
                for j in range(max_ncols):
                    if plot_original:
                        if i==0 and j==0:
                            if full_size:
                                show_image(self.img, ctx=ax[0,0])
                            else:
                                x = TensorImage(learn.dls.train.decode((self.x,))[0][0])
                                x.show(ctx=ax[0,0])
                            ax[0][0].set_title('original')
                            continue
                    plot_gcam(img=self.img, x=self.x, full_size=full_size,
                              gcam_map=self.gradcams[self.labels[label_idx]],
                              plt_axis=ax[i,j], alpha=alpha, learn=self.learn,
                              interpolation=interpolation, cmap=cmap)
                    title = self.labels[label_idx]
                    ax[i][j].set_title(f'{title}, {self.preds_dict[title] * 100:.02f}%')
                    label_idx += 1
                    if label_idx >= len(self.labels): break
        else:
            fig,ax = plt.subplots(nrows=1, ncols=max_ncols, figsize=figsize)
            plt.axis('off')

            for i in range(len(ax)):
                if plot_original:
                    if i==0 and full_size:
                        show_image(self.img, ctx=ax[0])
                        ax[0].set_title('original')
                        continue
                    elif i==0 and not full_size:
                        _ = plt_decoded(self.learn, self.x, ctx=ax[0])
                        ax[0].set_title('original')
                        continue
                plot_gcam(img=self.img, x=self.x, full_size=full_size,
                          gcam_map=self.gradcams[self.labels[label_idx]],
                          plt_axis=ax[i], alpha=alpha, learn=self.learn,
                          interpolation=interpolation, cmap=cmap)
                title = self.labels[label_idx]
                ax[i].set_title(f'{title}, {self.preds_dict[title] * 100:.02f}%')
                label_idx += 1